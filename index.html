<!DOCTYPE html>
<html lang="az">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#ffffff">
  <link rel="manifest" href="manifest.json">
  <title>S…ôsl…ô Doldurma (Whisper API)</title>
  <style>
    body { font-family: sans-serif; margin: 20px; }
    table { margin-bottom: 30px; border-collapse: collapse; width: 100%; }
    th, td { border: 1px solid #999; padding: 6px 10px; }
    th { background-color: #f0f0f0; }
    td:nth-child(2) { background-color: #fcfcfc; transition: background 0.4s; }
    td.filled { background-color: #d0ffd0 !important; font-weight: bold; }
    button { padding: 10px 20px; font-size: 16px; margin-right: 10px; }
    #live { margin-top: 10px; font-weight: bold; }
  </style>
</head>
<body>

<h2>üé§ S…ôsl…ô Doldurma (Whisper API)_1</h2>
<button onclick="startRecording()">üé§ Yaz / G√∂nd…ôr</button>
<div id="live">Canlƒ±: ‚Äî</div>

<table id="U1_table">
  <thead><tr><th colspan="2">QARACƒ∞Y∆èR</th></tr></thead>
  <tbody>
    <tr><td>√ñl√ß√ºl…ôri</td><td>---</td></tr>
    <tr><td>K…ônarlarƒ±</td><td>---</td></tr>
    <tr><td>Exogenliyi</td><td>---</td></tr>
    <tr><td>Strukturu</td><td>---</td></tr>
  </tbody>
</table>

<script>
let mediaRecorder;
let chunks = [];
const table = document.getElementById("U1_table");

const flatFieldMap = {
  "olculeri": "√∂l√ß√ºl…ôri",
  "olculerin": "√∂l√ß√ºl…ôri",
  "√∂l√ß√ºl…ôri": "√∂l√ß√ºl…ôri",
  "√∂l√ß√ºs√º": "√∂l√ß√ºl…ôri",
  "k…ônarlarƒ±": "k…ônarlarƒ±",
  "k…ônar": "k…ônarlarƒ±",
  "exogenliyi": "exogenliyi",
  "eksogenlik": "exogenliyi",
  "struktur": "strukturu",
  "strukturu": "strukturu"
};

function startRecording() {
  navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
    mediaRecorder = new MediaRecorder(stream);
    chunks = [];

    mediaRecorder.ondataavailable = e => chunks.push(e.data);
    mediaRecorder.onstop = () => {
      const blob = new Blob(chunks, { type: 'audio/webm' });
      sendToWhisper(blob);
    };

    mediaRecorder.start();
    document.getElementById("live").textContent = "Canlƒ±: Yazƒ±lƒ±r...";

    setTimeout(() => {
      mediaRecorder.stop();
    }, 5000);
  });
}

function sendToWhisper(blob) {
  const formData = new FormData();
  formData.append("file", blob, "audio.webm");
  formData.append("model", "whisper-1");

  fetch("https://api.openai.com/v1/audio/transcriptions", {
    method: "POST",
    headers: {
      "Authorization": "Bearer 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"
    },
    body: formData
  })
    .then(res => res.json())
    .then(data => {
      const text = data.text.toLowerCase();
      document.getElementById("live").textContent = "Canlƒ±: " + text;
      fillFields(text);
    })
    .catch(err => {
      console.error("X…ôta:", err);
      document.getElementById("live").textContent = "X…ôta ba≈ü verdi.";
    });
}

function fillFields(text) {
  const words = text.split(/\s+/);
  const rows = table.querySelectorAll("tbody tr");

  for (let i = 0; i < words.length - 1; i++) {
    const key = flatFieldMap[words[i]];
    const value = words[i + 1];
    if (key && value) {
      for (let row of rows) {
        if (row.cells[0].textContent.trim().toLowerCase() === key) {
          row.cells[1].textContent = value;
          row.cells[1].classList.add("filled");
        }
      }
    }
  }
}
</script>
</body>
</html>
